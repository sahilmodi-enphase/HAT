name: HAT_SRx2_ImageNet-pretrain
model_type: HATModel
scale: 2
num_gpu: 0  # set num_gpu: 0 for cpu mode
manual_seed: 0

datasets:
  test_1:  # the 1st test dataset
    name: test_19
    type: SingleImageDataset
    dataroot_lq: /Users/sahilmodi/Projects/Git_Repos/HAT/datasets/test_19
    io_backend:
      type: disk

  # test_2:  # the 2nd test dataset
  #   name: Set14
  #   type: PairedImageDataset
  #   dataroot_gt: ./datasets/Set14/GTmod2
  #   dataroot_lq: ./datasets/Set14/LRbicx2
  #   io_backend:
  #     type: disk

  # test_3:
  #   name: Urban100
  #   type: PairedImageDataset
  #   dataroot_gt: ./datasets/urban100/GTmod2
  #   dataroot_lq: ./datasets/urban100/LRbicx2
  #   io_backend:
  #     type: disk

  # test_4:
  #    name: BSDS100
  #    type: PairedImageDataset
  #    dataroot_gt: ./datasets/BSDS100/GTmod2
  #    dataroot_lq: ./datasets/BSDS100/LRbicx2
  #    io_backend:
  #      type: disk

  # test_5:
  #     name: Manga109
  #     type: PairedImageDataset
  #     dataroot_gt: ./datasets/manga109/GTmod2
  #     dataroot_lq: ./datasets/manga109/LRbicx2
  #     io_backend:
  #       type: disk

# network structures
network_g:
  type: HAT
  upscale: 2
  in_chans: 3
  img_size: 64
  window_size: 16
  compress_ratio: 3
  squeeze_factor: 30
  conv_scale: 0.01
  overlap_ratio: 0.5
  img_range: 1.
  depths: [6, 6, 6, 6, 6, 6]
  embed_dim: 180
  num_heads: [6, 6, 6, 6, 6, 6]
  mlp_ratio: 2
  upsampler: 'pixelshuffle'
  resi_connection: '1conv'


# path
path:
  pretrain_network_g: ./experiments/pretrained_models/HAT_SRx2_ImageNet-pretrain.pth
  strict_load_g: true
  param_key_g: 'params_ema'

# validation settings
val:
  save_img: true
  suffix: _HAT_SRx2_ImageNet  # add suffix to saved images, if None, use exp name
